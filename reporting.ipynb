{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcec132",
   "metadata": {},
   "source": [
    "## Reporting\n",
    "\n",
    "This module processes model-generated log files and extracts metrics such as ratios, precision, recall, confusion matrix values, and histogram data. The results are aggregated into structured CSV reports for further analysis or record-keeping.\n",
    "\n",
    " Main Functions:\n",
    "   - get_row_from_log: Parses individual log files to extract metrics.\n",
    "   - generates_csv_file: Writes global metric data to CSV.\n",
    "   - generates_csv_file_hist: Writes histogram data to CSV.\n",
    "   - generates_csv_files: Entry point for report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Import Section\n",
    "#\n",
    "# This section loads required Python libraries and modules used across \n",
    "# the reporting script.\n",
    "########################################################################\n",
    "\n",
    "from activity_constants import *  # Imports all constants defined in the local 'activity_constants' module\n",
    "\n",
    "import gc       # Provides access to garbage collection functionality (not used explicitly in this script)\n",
    "import os       # Enables interaction with the operating system, e.g., file path manipulation and directory listing\n",
    "\n",
    "import fnmatch  # Used to match filenames using Unix shell-style wildcards (e.g., for selecting log files)\n",
    "import csv      # Enables reading from and writing to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df509416",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# get_row_from_log: Extracts metrics and summary statistics from a model\n",
    "# log file, parsing each line depending on its expected content and \n",
    "# returns a structured list of values.\n",
    "#\n",
    "# Inputs:\n",
    "#   - model_folder: Path to the directory containing the log file.\n",
    "#   - file_name: Name of the log file to parse.\n",
    "#\n",
    "# Returns:\n",
    "#   - str_return: List containing filename, extracted metrics, and summary.\n",
    "########################################################################\n",
    "def get_row_from_log (model_folder, file_name):\n",
    "    str_return = [file_name]\n",
    "    # Using readlines()\n",
    "    file1 = open(model_folder + '/' + file_name , 'r')\n",
    "    Lines = file1.readlines()\n",
    "\n",
    "    count = 0\n",
    "    total_elements = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        print(\"Line{}: {}\".format(count, line))\n",
    "\n",
    "        #str_return = str_return + ','\n",
    "            \n",
    "        if (count >= 0 and  count <= 2):\n",
    "          str_return.append(line.split(' ')[2].replace('\\n', ''))\n",
    "        \n",
    "        elif (count == 3):\n",
    "            numnber_list = line.replace('[', '').replace(']', '').split(',')\n",
    "            numnber_list = [s.strip() for s in numnber_list]\n",
    "            #numnber_list = [s.replace('[', '') for s in numnber_list]\n",
    "            #numnber_list = [s.replace(']', '') for s in numnber_list]\n",
    "            \n",
    "            print(\"numnber_list: {}\".format(numnber_list))\n",
    "            str_return.append(numnber_list[1])\n",
    "            \n",
    "            for i in range (2,4):\n",
    "                if (len(numnber_list) >= i+1):\n",
    "                    str_return.append(numnber_list[i])\n",
    "                else:\n",
    "                    str_return.append('')\n",
    "                    \n",
    "        elif (count >= 4 and  count <= 5):\n",
    "            numnber_list = line.replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "            \n",
    "            print(\"numnber_list: {}\".format(numnber_list))\n",
    "            \n",
    "            for number in numnber_list:\n",
    "                if (len(number) > 0):\n",
    "                    str_return.append(number)\n",
    "                    \n",
    "                    print(\"numnber: {}\".format(number))\n",
    "                    total_elements = total_elements + (int)(number)\n",
    "        count += 1\n",
    "        \n",
    "    str_return.append(total_elements)\n",
    "    \n",
    "    print(\"output: {}\".format(str_return))\n",
    "    return str_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944281f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# generates_csv_file: Aggregates results from multiple global log files\n",
    "# into a single CSV report.\n",
    "#\n",
    "# Inputs:\n",
    "#   - p_model_folder: Directory path containing the log files.\n",
    "#   - file_filter: Pattern to match target log files.\n",
    "#   - file_output: Output CSV filename.\n",
    "#\n",
    "# Returns:\n",
    "#   - None (writes data directly to CSV file).\n",
    "########################################################################\n",
    "def generates_csv_file (p_model_folder, file_filter, file_output):\n",
    "    \n",
    "    print(\"Analyzing folder: {}\".format(p_model_folder))\n",
    "    print(\"Writting report: {}\".format(p_model_folder + '/' + file_output))\n",
    "\n",
    "    with open(p_model_folder + '/' + file_output, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['fila_name','Gobal ratio','Negative ratio','Positive ratio', 'Precision','Recall','F1','True Negatives','False Positives','False Negatives','True Positives', 'total elements'])\n",
    "        \n",
    "        for file in fnmatch.filter(os.listdir(p_model_folder), file_filter):\n",
    "            writer.writerow(get_row_from_log(p_model_folder, file))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f937e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# generates_csv_file_hist: Creates a CSV report summarizing histogram\n",
    "# data from model histogram log files.\n",
    "#\n",
    "# Inputs:\n",
    "#   - p_model_folder: Directory containing histogram log files.\n",
    "#   - file_filter: Pattern to identify histogram log files.\n",
    "#   - file_output: Name of the CSV file to be created.\n",
    "#\n",
    "# Returns:\n",
    "#   - None (writes histogram content to CSV).\n",
    "########################################################################\n",
    "def generates_csv_file_hist (p_model_folder, file_filter, file_output):\n",
    "    \n",
    "    print(\"Analyzing folder: {}\".format(p_model_folder))\n",
    "    print(\"Writting report: {}\".format(p_model_folder + '/' + file_output))\n",
    "\n",
    "    with open(p_model_folder + '/' + file_output, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        header = ['fila_name','hist_type']\n",
    "        file_list = fnmatch.filter(os.listdir(p_model_folder), file_filter);\n",
    "        \n",
    "        if (len(file_list) > 0):\n",
    "            file1 = open(p_model_folder + '/' + file_list[0] , 'r')\n",
    "            lines = file1.readlines()\n",
    "            num_elements = len(lines[0].split(','))\n",
    "            \n",
    "            print (str(num_elements))\n",
    "            \n",
    "            for i in range (num_elements):\n",
    "                header.append(str(i+1))\n",
    "            \n",
    "            writer.writerow(header)\n",
    "        \n",
    "            for file in file_list:\n",
    "                file1 = open(p_model_folder + '/' + file , 'r')\n",
    "                lines = file1.readlines()\n",
    "                #print (file)\n",
    "                line = \"{0},{1},{2}\".format(file, file.split(\"##\")[2].split(\".\")[0].split(\"_\")[1], lines[0])\n",
    "                #print (line)\n",
    "                csv_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# generates_csv_files: Orchestrates generation of both global and\n",
    "# histogram CSV reports for a given study and assay.\n",
    "#\n",
    "# Inputs:\n",
    "#   - p_model_folder: Root folder where the study folder resides.\n",
    "#   - p_study_name: Name of the study folder.\n",
    "#   - p_assay: Assay identifier used for file filtering.\n",
    "#\n",
    "# Returns:\n",
    "#   - None (invokes other CSV generation routines).\n",
    "########################################################################\n",
    "def generates_csv_files (p_model_folder, p_study_name, p_assay):\n",
    "    generates_csv_file_hist (model_folder + '/' + p_study_name, 'model_' + p_assay + '*##hist_*.log', 'report_hist.csv')\n",
    "    generates_csv_file (model_folder + '/' + p_study_name, 'model_' + p_assay + '*##global.log', 'report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8639f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generates_csv_files (model_folder, 'study_layer', '1806')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "generates_csv_files (model_folder, 'study_dense', '1806')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116b9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
